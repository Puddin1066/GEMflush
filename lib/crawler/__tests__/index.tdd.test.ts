/**
 * TDD Test: Web Crawler - Tests Drive Implementation
 * 
 * SPECIFICATION: Web Crawling Functionality
 * 
 * As a system
 * I want to crawl websites and extract business data
 * So that I can analyze businesses and build entities
 * 
 * IMPORTANT: These tests specify DESIRED behavior for web crawling.
 * Tests verify that crawling works correctly for business data extraction.
 * 
 * TDD Cycle: RED â†’ GREEN â†’ REFACTOR
 * Tests written to specify desired crawling behavior
 */

import { describe, it, expect, beforeEach, vi } from 'vitest';
import { webCrawler } from '../index';
import type { CrawlResult } from '@/lib/types/gemflush';

// Mock dependencies
vi.mock('../firecrawl-client', () => ({
  firecrawlClient: {
    crawlWithLLMExtraction: vi.fn(),
    getCrawlJobStatus: vi.fn(),
  },
}));

vi.mock('@/lib/utils/firecrawl-mock', () => ({
  shouldUseMockFirecrawl: vi.fn(() => false),
  generateMockFirecrawlCrawlResponse: vi.fn(),
}));

vi.mock('@/lib/utils/mock-crawl-data', () => ({
  shouldUseMockCrawlData: vi.fn(() => false),
  generateMockCrawlData: vi.fn(),
}));

vi.mock('@/lib/db/queries', () => ({
  updateCrawlJob: vi.fn(),
}));

describe('ðŸ”´ RED: Web Crawler - Desired Behavior Specification', () => {
  beforeEach(() => {
    vi.clearAllMocks();
    // Clear cache between tests to ensure clean state
    webCrawler.clearCache();
  });

  /**
   * SPECIFICATION 1: crawl() - MUST Crawl Website and Extract Data
   * 
   * DESIRED BEHAVIOR: crawl() MUST crawl a website and return structured
   * business data with name, description, contact info, and location.
   */
  describe('crawl', () => {
    it('MUST return successful crawl result with business data', async () => {
      // Arrange: Mock successful Firecrawl response
      const mockCrawlResponse = {
        success: true,
        data: [
          {
            url: 'https://example.com',
            llm_extraction: {
              businessName: 'Example Business',
              description: 'A test business',
              phone: '+1-555-123-4567',
              email: 'contact@example.com',
              city: 'San Francisco',
              state: 'CA',
              country: 'US',
            },
          },
        ],
      };

      const { firecrawlClient } = await import('../firecrawl-client');
      vi.mocked(firecrawlClient.crawlWithLLMExtraction).mockResolvedValue(mockCrawlResponse as any);

      // Act: Crawl website (TEST SPECIFIES DESIRED BEHAVIOR)
      const result = await webCrawler.crawl('https://example.com');

      // Assert: SPECIFICATION - MUST return successful result
      expect(result.success).toBe(true);
      expect(result.data).toBeDefined();
      expect(result.data?.name).toBe('Example Business');
      expect(result.data?.phone).toBe('+1-555-123-4567');
      expect(result.data?.email).toBe('contact@example.com');
      expect(result.data?.location?.city).toBe('San Francisco');
      expect(result.data?.location?.state).toBe('CA');
      expect(result.url).toBe('https://example.com');
      expect(result.crawledAt).toBeInstanceOf(Date);
    });

    it('MUST handle multi-page crawl and aggregate data', async () => {
      // Arrange: Mock multi-page crawl response
      const mockCrawlResponse = {
        success: true,
        data: [
          {
            url: 'https://example.com',
            llm_extraction: {
              businessName: 'Example Business',
              description: 'Main page description',
              phone: '+1-555-123-4567',
            },
          },
          {
            url: 'https://example.com/about',
            llm_extraction: {
              description: 'About page with more details',
              city: 'San Francisco',
              state: 'CA',
            },
          },
          {
            url: 'https://example.com/services',
            llm_extraction: {
              services: ['Service 1', 'Service 2'],
            },
          },
        ],
      };

      const { firecrawlClient } = await import('../firecrawl-client');
      vi.mocked(firecrawlClient.crawlWithLLMExtraction).mockResolvedValue(mockCrawlResponse as any);

      // Act: Crawl website (TEST SPECIFIES DESIRED BEHAVIOR)
      const result = await webCrawler.crawl('https://example.com');

      // Assert: SPECIFICATION - MUST aggregate multi-page data
      expect(result.success).toBe(true);
      expect(result.data?.name).toBe('Example Business');
      expect(result.data?.description).toBeDefined(); // Should have description
      expect(result.data?.location?.city).toBe('San Francisco');
      expect(result.data?.services).toContain('Service 1');
      expect(result.data?.services).toContain('Service 2');
    });

    it('MUST handle async crawl jobs with polling', async () => {
      // Arrange: Mock async job response
      const mockJobResponse = {
        success: true,
        id: 'fc-job-123',
        data: [],
      };

      const mockJobStatus = {
        success: true,
        status: 'completed',
        data: [
          {
            url: 'https://example.com',
            llm_extraction: {
              businessName: 'Example Business',
              description: 'A test business',
            },
          },
        ],
        completed: 1,
        total: 1,
      };

      const { firecrawlClient } = await import('../firecrawl-client');
      vi.mocked(firecrawlClient.crawlWithLLMExtraction).mockResolvedValue(mockJobResponse as any);
      vi.mocked(firecrawlClient.getCrawlJobStatus)
        .mockResolvedValueOnce({
          success: true,
          status: 'processing',
          completed: 0,
          total: 1,
        } as any)
        .mockResolvedValueOnce(mockJobStatus as any);

      // Act: Crawl website (TEST SPECIFIES DESIRED BEHAVIOR)
      const result = await webCrawler.crawl('https://example.com');

      // Assert: SPECIFICATION - MUST poll and return results
      expect(result.success).toBe(true);
      expect(result.data?.name).toBe('Example Business');
      expect(firecrawlClient.getCrawlJobStatus).toHaveBeenCalledWith('fc-job-123');
    });

    it('MUST validate URL format and reject invalid URLs', async () => {
      // Arrange: Invalid URL
      const invalidUrl = 'not-a-url';

      // Act: Crawl invalid URL (TEST SPECIFIES DESIRED BEHAVIOR)
      const result = await webCrawler.crawl(invalidUrl);

      // Assert: SPECIFICATION - MUST reject invalid URLs
      expect(result.success).toBe(false);
      expect(result.error).toBeDefined();
    });

    it('MUST use cache for recently crawled URLs', async () => {
      // Arrange: First crawl
      const mockCrawlResponse = {
        success: true,
        data: [
          {
            url: 'https://example.com',
            llm_extraction: {
              businessName: 'Example Business',
            },
          },
        ],
      };

      const { firecrawlClient } = await import('../firecrawl-client');
      vi.mocked(firecrawlClient.crawlWithLLMExtraction).mockResolvedValue(mockCrawlResponse as any);

      // Act: Crawl twice (TEST SPECIFIES DESIRED BEHAVIOR)
      const result1 = await webCrawler.crawl('https://example.com');
      const result2 = await webCrawler.crawl('https://example.com');

      // Assert: SPECIFICATION - MUST use cache on second call
      expect(result1.success).toBe(true);
      expect(result2.success).toBe(true);
      // Second call should use cache, so crawlWithLLMExtraction should only be called once
      expect(firecrawlClient.crawlWithLLMExtraction).toHaveBeenCalledTimes(1);
    });

    it('MUST fallback to mock data when Firecrawl fails', async () => {
      // Arrange: Firecrawl failure, mock data available
      const { firecrawlClient } = await import('../firecrawl-client');
      const { shouldUseMockCrawlData, generateMockCrawlData } = await import('@/lib/utils/mock-crawl-data');
      
      vi.mocked(firecrawlClient.crawlWithLLMExtraction).mockRejectedValue(new Error('API error'));
      vi.mocked(shouldUseMockCrawlData).mockReturnValue(true);
      vi.mocked(generateMockCrawlData).mockReturnValue({
        name: 'Mock Business',
        description: 'Mock description',
        phone: '+1-555-000-0000',
      });

      // Act: Crawl with Firecrawl failure (TEST SPECIFIES DESIRED BEHAVIOR)
      const result = await webCrawler.crawl('https://example.com');

      // Assert: SPECIFICATION - MUST fallback to mock data
      expect(result.success).toBe(true);
      expect(result.data?.name).toBe('Mock Business');
    });

    it('MUST update crawl job progress when jobId provided', async () => {
      // Arrange: Mock crawl with jobId
      const mockCrawlResponse = {
        success: true,
        data: [
          {
            url: 'https://example.com',
            llm_extraction: {
              businessName: 'Example Business',
            },
          },
        ],
      };

      const { firecrawlClient } = await import('../firecrawl-client');
      const { updateCrawlJob } = await import('@/lib/db/queries');
      
      vi.mocked(firecrawlClient.crawlWithLLMExtraction).mockResolvedValue(mockCrawlResponse as any);

      // Act: Crawl with jobId (TEST SPECIFIES DESIRED BEHAVIOR)
      await webCrawler.crawl('https://example.com', 123);

      // Assert: SPECIFICATION - MUST update job progress
      expect(updateCrawlJob).toHaveBeenCalled();
    });

    it('MUST handle HTTP and HTTPS URLs only', async () => {
      // Arrange: Non-HTTP URL
      const invalidUrl = 'ftp://example.com';

      // Act: Crawl non-HTTP URL (TEST SPECIFIES DESIRED BEHAVIOR)
      const result = await webCrawler.crawl(invalidUrl);

      // Assert: SPECIFICATION - MUST reject non-HTTP URLs
      expect(result.success).toBe(false);
      expect(result.error).toContain('HTTP');
    });

    it('MUST aggregate services from multiple pages', async () => {
      // Arrange: Multi-page crawl with services
      const mockCrawlResponse = {
        success: true,
        data: [
          {
            url: 'https://example.com',
            llm_extraction: {
              businessName: 'Example Business',
              services: ['Service A', 'Service B'],
            },
          },
          {
            url: 'https://example.com/services',
            llm_extraction: {
              services: ['Service C', 'Service A'], // Service A is duplicate
            },
          },
        ],
      };

      const { firecrawlClient } = await import('../firecrawl-client');
      vi.mocked(firecrawlClient.crawlWithLLMExtraction).mockResolvedValue(mockCrawlResponse as any);

      // Act: Crawl website (TEST SPECIFIES DESIRED BEHAVIOR)
      const result = await webCrawler.crawl('https://example.com');

      // Assert: SPECIFICATION - MUST aggregate and deduplicate services
      expect(result.success).toBe(true);
      expect(result.data?.services).toContain('Service A');
      expect(result.data?.services).toContain('Service B');
      expect(result.data?.services).toContain('Service C');
      // Should deduplicate Service A
      const serviceACount = result.data?.services?.filter(s => s === 'Service A').length;
      expect(serviceACount).toBe(1);
    });

    it('MUST merge social links from multiple pages', async () => {
      // Arrange: Multi-page crawl with social links
      const mockCrawlResponse = {
        success: true,
        data: [
          {
            url: 'https://example.com',
            llm_extraction: {
              businessName: 'Example Business',
              socialMedia: {
                facebook: 'https://facebook.com/example',
                twitter: '@example',
              },
            },
          },
          {
            url: 'https://example.com/contact',
            llm_extraction: {
              socialMedia: {
                linkedin: 'https://linkedin.com/company/example',
                instagram: '@example_insta',
              },
            },
          },
        ],
      };

      const { firecrawlClient } = await import('../firecrawl-client');
      vi.mocked(firecrawlClient.crawlWithLLMExtraction).mockResolvedValue(mockCrawlResponse as any);

      // Act: Crawl website (TEST SPECIFIES DESIRED BEHAVIOR)
      const result = await webCrawler.crawl('https://example.com');

      // Assert: SPECIFICATION - MUST merge social links
      expect(result.success).toBe(true);
      expect(result.data?.socialLinks?.facebook).toBe('https://facebook.com/example');
      expect(result.data?.socialLinks?.twitter).toBe('@example');
      expect(result.data?.socialLinks?.linkedin).toBe('https://linkedin.com/company/example');
      expect(result.data?.socialLinks?.instagram).toBe('@example_insta');
    });

    it('MUST prefer most complete contact information', async () => {
      // Arrange: Multi-page crawl with varying contact info completeness
      const mockCrawlResponse = {
        success: true,
        data: [
          {
            url: 'https://example.com',
            llm_extraction: {
              businessName: 'Example Business',
              phone: '+1-555-123-4567',
              // Missing email and address
            },
          },
          {
            url: 'https://example.com/contact',
            llm_extraction: {
              phone: '+1-555-123-4567',
              email: 'contact@example.com',
              address: '123 Main St',
              // More complete contact info
            },
          },
        ],
      };

      const { firecrawlClient } = await import('../firecrawl-client');
      vi.mocked(firecrawlClient.crawlWithLLMExtraction).mockResolvedValue(mockCrawlResponse as any);

      // Act: Crawl website (TEST SPECIFIES DESIRED BEHAVIOR)
      const result = await webCrawler.crawl('https://example.com');

      // Assert: SPECIFICATION - MUST prefer most complete contact info
      expect(result.success).toBe(true);
      expect(result.data?.phone).toBe('+1-555-123-4567');
      expect(result.data?.email).toBe('contact@example.com');
      expect(result.data?.address).toBe('123 Main St');
    });

    /**
     * SPECIFICATION: Handle Network Errors Gracefully
     * 
     * Given: Network error during crawl
     * When: Crawl is attempted
     * Then: Error is caught and returned gracefully without crashing
     */
    it('MUST handle network errors gracefully', async () => {
      // Arrange: Network error - Firecrawl client falls back to mocks
      const { firecrawlClient } = await import('../firecrawl-client');
      const { shouldUseMockCrawlData, generateMockCrawlData } = await import('@/lib/utils/mock-crawl-data');
      
      // Firecrawl client falls back to mocks on errors, so we mock that behavior
      vi.mocked(firecrawlClient.crawlWithLLMExtraction).mockResolvedValue({
        success: true,
        data: [
          {
            url: 'https://example.com',
            extract: {
              businessName: 'Fallback Business',
              description: 'Fallback description',
            },
          },
        ],
      } as any);
      vi.mocked(shouldUseMockCrawlData).mockReturnValue(false);

      // Act: Crawl with network error (TEST DRIVES IMPLEMENTATION)
      // Note: Firecrawl client handles errors internally and falls back to mocks
      const result = await webCrawler.crawl('https://example.com');

      // Assert: SPECIFICATION - MUST handle network errors gracefully
      // Implementation falls back to mocks, so we get a successful result
      expect(result.success).toBe(true);
      expect(result.data).toBeDefined();
    });
  });
});

